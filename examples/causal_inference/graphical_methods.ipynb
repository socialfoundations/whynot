{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Causal Graphs with WhyNot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WhyNot comes equipped with tools to automatically generate *the causal graph* associated with experiments on the dynamical system simulators. Using ideas from recent work in [automatic differentiation](https://github.com/HIPS/autograd), WhyNot traces the simulator execution and the user-provided functions to select covariates, assign treatment, and compute the desired outcome to build up the corresponding causal graph. The graph is returned with the dataset as a Networkx graph object. \n",
    "\n",
    "This notebook demonstrates how to construct and manipulate the causal graph, and then combines the causal graph with the recent [DoWhy](https://github.com/microsoft/dowhy) package to perform causal inference using a graphical approach.\n",
    "\n",
    "\n",
    "**Note**: This feature is still experimental, and there are likely a few rough edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import copy\n",
    "\n",
    "import whynot as wn\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "# To enable tracing of user-generated functions to construct the experiment,\n",
    "# we have to import a thinly-wrapped version of numpy\n",
    "import whynot.traceable_numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the experiment\n",
    "\n",
    "To showcase graph construction, we conduct a simple experiment on the Lotka-Volterra simulator to illustrate how to use causal graph construction. \n",
    "- The Lotka-Volterra simulator consists of two states, the rabbit population and the fox population. \n",
    "- The dynamics of the simulator are fully connected, so both the number of rabbits and foxes at time $t$ influence the number of rabbits at time $t+1$ and similarly for foxes. \n",
    "- We run the simulator for six time steps. \n",
    "- On the third time steps, we intervene to reduce the `fox_growth` parameter, i.e. the factor describing how rabbits are needed to sustain a fox. \n",
    "- To generate confounding, treatment is more likely when the fox poulation at time step 3 is low. \n",
    "- The outcome is the total fox population at time 6.\n",
    "- The observed covariates is the fox and rabbit population at the time of intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined helper functions for the experiment\n",
    "def sample_initial_states(rng):\n",
    "    \"\"\"Initial state distribution\"\"\"\n",
    "    rabbits = rng.randint(10, 100)\n",
    "    # Ensure the number of rabbits is greater than number of foxes.\n",
    "    foxes = rng.uniform(0.1, 0.8) * rabbits\n",
    "    return wn.lotka_volterra.State(rabbits=rabbits, foxes=foxes)\n",
    "\n",
    "def soft_threshold(x, threshold, r=20):\n",
    "    \"\"\"A continuous relaxation of the threshold function. If x > tau, return ~1, if x < tau, returns ~0.\"\"\"\n",
    "    return 1. / (np.exp(r * (threshold  - x)) + 1)\n",
    "\n",
    "\n",
    "def confounded_propensity_scores(untreated_run, intervention):\n",
    "    \"\"\"Return confounded treatment assignment probability.\n",
    "    Treatment is more likely for runs with low initial fox population.\n",
    "    \"\"\"\n",
    "    return 0.3 + 0.4 * (1. - soft_threshold(untreated_run[intervention.time].foxes, threshold=7))\n",
    "\n",
    "def covariate_observer(run, intervention):\n",
    "    \"\"\"Return the full state at the time of intervention and the previous time step.\"\"\"\n",
    "    prev_state = run[max(intervention.time - 1, 0)].values()\n",
    "    curr_state = run[intervention.time].values()\n",
    "    return np.concatenate([prev_state, curr_state])\n",
    "\n",
    "def outcome_extractor(run, config):\n",
    "    \"\"\"Final fox population.\"\"\"\n",
    "    return run[config.end_time].foxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = wn.DynamicsExperiment(\n",
    "    name=\"lotka_volterra_confounding\",\n",
    "    description=(\"Determine effect of reducing rabbits needed to sustain a fox. Treament confounded by initial fox population.\"),\n",
    "    simulator=wn.lotka_volterra,\n",
    "    simulator_config=wn.lotka_volterra.Config(fox_growth=0.75, delta_t=1, end_time=6),\n",
    "    intervention=wn.lotka_volterra.Intervention(time=3, fox_growth=0.4),\n",
    "    state_sampler=sample_initial_states,\n",
    "    propensity_scorer=confounded_propensity_scores,\n",
    "    outcome_extractor=outcome_extractor,\n",
    "    covariate_builder=covariate_observer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data and causal graphs\n",
    "\n",
    "To generate the causal graph associated with the experiment, pass `causal_graph=True` into the `experiment.run` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = exp.run(num_samples=100, causal_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The causal graph is a networkx object\n",
    "graph = dset.causal_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the causal graph\n",
    "\n",
    "The nodes in the causal graph are the state variables at each time step, the treatment, the outcome, and the configuration parameters, which are prefixed with `PARAM`. The edges correspond to causal dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rabbits_0\n",
      "foxes_0\n",
      "PARAM:rabbit_growth_0\n",
      "PARAM:rabbit_death_0\n",
      "PARAM:fox_death_0\n",
      "PARAM:fox_growth_0\n",
      "Treatment\n",
      "Outcome\n"
     ]
    }
   ],
   "source": [
    "nodes = list(graph.nodes)\n",
    "for node in list(nodes)[:6] + nodes[-2:]:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed covariates are foxes and rabbits at the step before intervention, i.e. step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rabbits_2\n",
      "foxes_2\n",
      "rabbits_3\n",
      "foxes_3\n",
      "Treatment\n",
      "Outcome\n"
     ]
    }
   ],
   "source": [
    "for node, data in graph.nodes.items():\n",
    "    if data[\"observed\"] == \"yes\":\n",
    "        print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the edges: Treatment only directly depends on the fox population at time 3 and the outcome only depends on the final fox population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InEdgeDataView([('foxes_3', 'Treatment')])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.in_edges(\"Treatment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InEdgeDataView([('foxes_6', 'Outcome')])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.in_edges(\"Outcome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating treatwith effects with [DoWhy ](https://github.com/microsoft/dowhy)\n",
    "\n",
    "With access to the causal graph, we can use causal inference methods based on graphical analysis. We make use of the [DoWhy package](https://github.com/microsoft/dowhy) to demonstrate how combine data from WhyNot with graphical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install dowhy\n",
    "from dowhy.causal_model import CausalModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the causal model\n",
    "\n",
    "Convert the dataset into a pandas dataframe and build the DoWhy `CausalModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rabbits_2</th>\n",
       "      <th>foxes_2</th>\n",
       "      <th>rabbits_3</th>\n",
       "      <th>foxes_3</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.132412</td>\n",
       "      <td>7.967909</td>\n",
       "      <td>0.237851</td>\n",
       "      <td>1.800588</td>\n",
       "      <td>True</td>\n",
       "      <td>0.023511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.355919</td>\n",
       "      <td>9.976526</td>\n",
       "      <td>9.176512</td>\n",
       "      <td>3.850267</td>\n",
       "      <td>True</td>\n",
       "      <td>4.956715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.354260</td>\n",
       "      <td>13.091206</td>\n",
       "      <td>9.602428</td>\n",
       "      <td>28.393787</td>\n",
       "      <td>False</td>\n",
       "      <td>1.497052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.336373</td>\n",
       "      <td>11.164037</td>\n",
       "      <td>18.109169</td>\n",
       "      <td>18.462397</td>\n",
       "      <td>True</td>\n",
       "      <td>3.016362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.195988</td>\n",
       "      <td>7.860133</td>\n",
       "      <td>0.353709</td>\n",
       "      <td>1.787702</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rabbits_2    foxes_2  rabbits_3    foxes_3  Treatment   Outcome\n",
       "0   0.132412   7.967909   0.237851   1.800588       True  0.023511\n",
       "1   6.355919   9.976526   9.176512   3.850267       True  4.956715\n",
       "2  54.354260  13.091206   9.602428  28.393787      False  1.497052\n",
       "3  33.336373  11.164037  18.109169  18.462397       True  3.016362\n",
       "4   0.195988   7.860133   0.353709   1.787702       True  0.025302"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.concatenate([dset.covariates, dset.treatments.reshape(-1, 1),\n",
    "                       dset.outcomes.reshape(-1, 1)], axis=1)\n",
    "df = pd.DataFrame(data, columns=graph.graph[\"covariate_names\"] + [\"Treatment\", \"Outcome\"])\n",
    "df[\"Treatment\"] = df[\"Treatment\"].astype(\"bool\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DoWhy expects a direct edge from Treatment->Outcome\n",
    "graphcopy = copy.deepcopy(graph)\n",
    "graphcopy.add_edges_from([(\"Treatment\", \"Outcome\")])\n",
    "del graphcopy.graph[\"covariate_names\"]\n",
    "nx.write_gml(graphcopy, \"assets/lotka_volterra_graph.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dowhy.causal_model:Model to find the causal effect of treatment ['Treatment'] on outcome ['Outcome']\n"
     ]
    }
   ],
   "source": [
    "model = CausalModel(\n",
    "    data=df,\n",
    "    treatment=\"Treatment\",\n",
    "    outcome=\"Outcome\",\n",
    "    graph=\"assets/lotka_volterra_graph.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify causal effects with the backdoor criteria\n",
    "\n",
    "Identify causal effect and return target estimands. There are unobserved common causes, but there exists a set of variables that blocks all backdoor paths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dowhy.causal_identifier:Common causes of treatment and outcome:['PARAM:fox_growth_2', 'PARAM:fox_growth_1', 'PARAM:rabbit_growth_1', 'rabbits_2', 'PARAM:rabbit_death_0', 'foxes_3', 'PARAM:fox_death_0', 'foxes_1', 'PARAM:rabbit_death_1', 'PARAM:fox_growth_0', 'PARAM:fox_death_2', 'rabbits_1', 'rabbits_0', 'PARAM:rabbit_death_2', 'foxes_2', 'PARAM:rabbit_growth_0', 'PARAM:fox_death_1', 'foxes_0']\n",
      "WARNING:dowhy.causal_identifier:If this is observed data (not from a randomized experiment), there might always be missing confounders. Causal effect cannot be identified perfectly.\n",
      "INFO:dowhy.causal_identifier:Continuing by ignoring these unobserved confounders because proceed_when_unidentifiable flag is True.\n",
      "INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimand type: nonparametric-ate\n",
      "### Estimand : 1\n",
      "Estimand name: backdoor\n",
      "Estimand expression:\n",
      "     d                                                      \n",
      "────────────(Expectation(Outcome|rabbits_2,foxes_3,foxes_2))\n",
      "d[Treatment]                                                \n",
      "Estimand assumption 1, Unconfoundedness: If U→{Treatment} and U→Outcome then P(Outcome|Treatment,rabbits_2,foxes_3,foxes_2,U) = P(Outcome|Treatment,rabbits_2,foxes_3,foxes_2)\n",
      "### Estimand : 2\n",
      "Estimand name: iv\n",
      "No such variable found!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "print(identified_estimand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating treatment effects \n",
    "\n",
    "Estimate treatment effects with propensity score matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dowhy.causal_estimator:INFO: Using Propensity Score Matching Estimator\n",
      "INFO:dowhy.causal_estimator:b: Outcome~Treatment+rabbits_2+foxes_3+foxes_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Causal Estimate ***\n",
      "\n",
      "## Target estimand\n",
      "Estimand type: nonparametric-ate\n",
      "### Estimand : 1\n",
      "Estimand name: backdoor\n",
      "Estimand expression:\n",
      "     d                                                      \n",
      "────────────(Expectation(Outcome|rabbits_2,foxes_3,foxes_2))\n",
      "d[Treatment]                                                \n",
      "Estimand assumption 1, Unconfoundedness: If U→{Treatment} and U→Outcome then P(Outcome|Treatment,rabbits_2,foxes_3,foxes_2,U) = P(Outcome|Treatment,rabbits_2,foxes_3,foxes_2)\n",
      "### Estimand : 2\n",
      "Estimand name: iv\n",
      "No such variable found!\n",
      "\n",
      "## Realized estimand\n",
      "b: Outcome~Treatment+rabbits_2+foxes_3+foxes_2\n",
      "## Estimate\n",
      "Value: -2.8277594094821\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miller_john/anaconda3/envs/whynot/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Estimate the target estimand using a statistical method.\n",
    "estimate = model.estimate_effect(identified_estimand,\n",
    "                                 control_value=0,\n",
    "                                 treatment_value=1,\n",
    "                                 target_units=\"ate\",\n",
    "                                 effect_modifiers=graph.graph[\"covariate_names\"],\n",
    "                                 method_name=\"backdoor.propensity_score_matching\")\n",
    "print(estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True average treatment effect: -3.41\n"
     ]
    }
   ],
   "source": [
    "print(f\"True average treatment effect: {np.mean(dset.true_effects):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
