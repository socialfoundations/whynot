{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis with the causalsens Package\n",
    "\n",
    "In this notebook, we explore sensitivity analysis using the R [causalsens](https://cran.r-project.org/web/packages/causalsens/index.html) package. Sensitivity analysis is a way to quantitatively evaluate the amount of potential biases in causal inference results. This is important because most causal inference algorithms require an ignorability assumption, where the treated units are comparable to the control units. We are often uncertain of the validity of this assumption.\n",
    "\n",
    "See the [paper](https://www.mattblackwell.org/files/papers/causalsens.pdf) for more technical details.\n",
    "\n",
    "We begin with some imports of standard data science libraries, the `whynot` package, and various `rpy2` packages in order to use the R package in the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import whynot as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "package_name = \"causalsens\"\n",
    "\n",
    "# Try-except block to install package if we have not already installed it\n",
    "try:\n",
    "    pkg = importr(package_name)\n",
    "except:\n",
    "    ro.r(f'install.packages(\"{package_name}\")')\n",
    "    pkg = importr(package_name)\n",
    "\n",
    "stats = importr('stats')\n",
    "base = importr('base')\n",
    "grdevices = importr('grDevices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We work with the Opipoid Unobserved Confounding Experiment. We get our dataset and the estimated effects using the `causal_suite`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "exp = wn.opioid.UnobservedConfounding\n",
    "dset = exp.run(num_samples=num_samples)\n",
    "estimated_effects = wn.causal_suite(dset.covariates, dset.treatments, dset.outcomes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the true average treatment effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-16590.944766502176"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dset.true_effects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the estimates of the average treatment effect using the various algorithms in our causal suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ols\n",
      "-12815.999660766945\n",
      "propensity_score_matching\n",
      "9253.106692397596\n",
      "propensity_weighted_ols\n",
      "-15337.879272539343\n",
      "causal_forest\n",
      "-18293.209287837348\n"
     ]
    }
   ],
   "source": [
    "for key in estimated_effects:\n",
    "    print(key)\n",
    "    print(estimated_effects[key].ate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We place the data into an R dataframe, create a regression model for the outcomes, a propensity score model (a logistic regression), and create a range for the $\\alpha$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'x1': dset.covariates[:, 0], 'x2': dset.covariates[:, 1], 'y': dset.outcomes, 'z': dset.treatments}\n",
    "dataf = ro.DataFrame(d)\n",
    "\n",
    "linear_model = stats.lm(\"y ~ x1 + x2 + z\", data=dataf)\n",
    "p_model = stats.glm(\"z ~ x1 + x2\", data=dataf, family=stats.binomial())\n",
    "\n",
    "alpha = np.arange(-4500, 4500, 250)\n",
    "ll_sens = pkg.causalsens(linear_model, p_model, ro.Formula('~ x1 + x2'), data=dataf, alpha=alpha, confound=pkg.one_sided_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the estimated effect against the amount of raw confounding (in terms of $\\alpha$) into a file and display it in Markdown. We can see that the true effect is contained in the confidence bounds for all values of $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grdevices.png(file=\"plots/amt_confounding.png\", width=512, height=512)\n",
    "ro.r.plot(ll_sens, type=\"raw\", bty=\"n\")\n",
    "grdevices.dev_off();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plots/amt_confounding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grdevices.png(file=\"plots/var_confounding.png\", width=512, height=512)\n",
    "ro.r.plot(ll_sens, type=\"r.squared\", bty=\"n\")\n",
    "grdevices.dev_off();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also plot the estimated effect in terms of the variance explained by the confounding. Again, the true effect is contained in the confidence bounds for all values of $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plots/var_confounding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we change the number of datapoints in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-16599.097457592823"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = 500\n",
    "exp = wn.opioid.UnobservedConfounding\n",
    "dset = exp.run(num_samples=num_samples)\n",
    "np.mean(dset.true_effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(dset, num_points):\n",
    "    d = {'x1': dset.covariates[:num_points, 0], 'x2': dset.covariates[:num_points, 1], 'y': dset.outcomes[:num_points], 'z': dset.treatments[:num_points]}\n",
    "    dataf = ro.DataFrame(d)\n",
    "\n",
    "    linear_model = stats.lm(\"y ~ x1 + x2 + z\", data=dataf)\n",
    "    p_model = stats.glm(\"z ~ x1 + x2\", data=dataf, family=stats.binomial())\n",
    "\n",
    "    alpha = np.arange(-4500, 4500, 250)\n",
    "    ll_sens = pkg.causalsens(linear_model, p_model, ro.Formula('~ x1 + x2'), data=dataf, alpha=alpha, confound=pkg.one_sided_att)\n",
    "    grdevices.png(file=\"plots/amt_confounding_\" + str(num_points) + \".png\", width=512, height=512)\n",
    "    ro.r.plot(ll_sens, type=\"raw\", bty=\"n\")\n",
    "    grdevices.dev_off();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we only have 100 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(dset, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plots/amt_confounding_100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we only have 200 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(dset, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plots/amt_confounding_200.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have 500 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(dset, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plots/amt_confounding_500.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the confidence intervals of the estimated effect shrink with an increase in the size of the dataset. For 200 and 500 datapoints, the confidence interval does not contain the true effect for many values of confounding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
