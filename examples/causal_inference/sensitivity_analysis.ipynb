{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis with the *causalsens* Package\n",
    "\n",
    "In this notebook, we explore sensitivity analysis using the R [causalsens](https://cran.r-project.org/web/packages/causalsens/index.html) package. Sensitivity analysis is an attempt to quantitatively evaluate the amount of potential biases in causal inference results. This is important because most causal inference algorithms require an ignorability assumption, where the treated units are comparable to the control units. We are often uncertain of the validity of this assumption.\n",
    "\n",
    "See the [paper](https://www.mattblackwell.org/files/papers/causalsens.pdf) for more technical details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miller_john/anaconda3/envs/whynot/lib/python3.7/site-packages/rpy2/robjects/pandas2ri.py:14: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import Index as PandasIndex\n",
      "/Users/miller_john/anaconda3/envs/whynot/lib/python3.7/site-packages/rpy2/robjects/pandas2ri.py:34: UserWarning: pandas >= 1.0 is not supported.\n",
      "  warnings.warn('pandas >= 1.0 is not supported.')\n",
      "/Users/miller_john/anaconda3/envs/whynot/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rpy2.robjects.packages as rpackages\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import numpy2ri, pandas2ri\n",
    "numpy2ri.activate()\n",
    "pandas2ri.activate()\n",
    "\n",
    "import whynot as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miller_john/anaconda3/envs/whynot/lib/python3.7/site-packages/rpy2/robjects/vectors.py:927: UserWarning: R object inheriting from \"POSIXct\" but without attribute \"tzone\".\n",
      "  warnings.warn('R object inheriting from \"POSIXct\" but without '\n"
     ]
    }
   ],
   "source": [
    "package_name = \"causalsens\"\n",
    "try:\n",
    "    causalsens = rpackages.importr(package_name)\n",
    "except:\n",
    "    utils = rpackages.importr(\"utils\")\n",
    "    utils.chooseCRANmirror(ind=1)\n",
    "    utils.install_packages(package_name)\n",
    "    causalsens = importr(package_name)\n",
    "\n",
    "stats = rpackages.importr('stats')\n",
    "base = rpackages.importr('base')\n",
    "grdevices = rpackages.importr('grDevices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating confounded data\n",
    "\n",
    "We generate data with *unobserved* confounding using the `wn.opioid.UnobservedConfounding` experiment on the [opioid simulator](https://whynot-docs.readthedocs-hosted.com/en/latest/simulators.html#opioid-simulator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = wn.opioid.UnobservedConfounding.run(num_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True average treatment effect: -16589.00 opioid deaths\n"
     ]
    }
   ],
   "source": [
    "print(f\"True average treatment effect: {np.mean(dset.true_effects):.2f} opioid deaths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating treatment effects\n",
    "\n",
    "We compute estimated treatment effects on this dataset using the collection of estimators provided in the `causal_suite`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ols: -14365.12\n",
      "propensity_score_matching: -682.56\n",
      "propensity_weighted_ols: -15721.77\n",
      "causal_forest: -8832.66\n"
     ]
    }
   ],
   "source": [
    "estimated_effects = wn.causal_suite(dset.covariates, dset.treatments, dset.outcomes)\n",
    "for estimator, estimate in estimated_effects.items():\n",
    "    print(f\"{estimator}: {estimate.ate:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running sensitivity analysis\n",
    "\n",
    "We perform a sensivity analysis using the *causalsens* package. To do this, we first fit a regression model for the outcomes, as well as a propensity score model (a logistic regression). We then compute interval bounds for the treatment effect, *accounting for unobserved confounding* via a *confounding function* that is parameterized by a single scalar, $\\alpha$. \n",
    "\n",
    "When $\\alpha > 0$, observed potential outcomes $Y$ are on average higher than their conterfactuals for all $X$, and similarly for $\\alpha < 0$. The setting $\\alpha = 0$ corresponds to no unobserved confounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ro.DataFrame({\n",
    "    'x1': dset.covariates[:, 0],\n",
    "    'x2': dset.covariates[:, 1], \n",
    "    'y': dset.outcomes,\n",
    "    'z': dset.treatments})\n",
    "\n",
    "linear_model = stats.lm(\"y ~ x1 + x2 + z\", data=df)\n",
    "p_model = stats.glm(\"z ~ x1 + x2\", data=df, family=stats.binomial())\n",
    "\n",
    "alpha = np.arange(-4500, 4500, 250)\n",
    "ll_sens = causalsens.causalsens(linear_model, p_model, ro.Formula('~ x1 + x2'),\n",
    "                                data=df, alpha=alpha, confound=causalsens.one_sided_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting sensitivity bounds\n",
    "We plot the estimated effect against the amount of raw confounding (in terms of $\\alpha$) into a file and display it in Markdown. We can see that the true effect is contained in the confidence bounds for all values of $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grdevices.png(file=\"assets/sensitivity_plots/amt_confounding.png\", width=512, height=512)\n",
    "ro.r.plot(ll_sens, type=\"raw\", bty=\"n\")\n",
    "grdevices.dev_off();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/sensitivity_plots/amt_confounding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grdevices.png(file=\"assets/sensitivity_plots/var_confounding.png\", width=512, height=512)\n",
    "ro.r.plot(ll_sens, type=\"r.squared\", bty=\"n\")\n",
    "grdevices.dev_off();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also plot the estimated effect in terms of the variance explained by the confounding. Again, the true effect is contained in the confidence bounds for all values of $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/sensitivity_plots/var_confounding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting sensitivity analysis as sample size varies\n",
    "\n",
    "Let's see what happens when we change the number of datapoints in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True effect: -16590.45\n"
     ]
    }
   ],
   "source": [
    "exp = wn.opioid.UnobservedConfounding\n",
    "dset = exp.run(num_samples=500)\n",
    "print(f\"True effect: {np.mean(dset.true_effects):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(dset, num_points):\n",
    "    df = ro.DataFrame({\n",
    "        'x1': dset.covariates[:num_points, 0],\n",
    "        'x2': dset.covariates[:num_points, 1],\n",
    "        'y': dset.outcomes[:num_points],\n",
    "        'z': dset.treatments[:num_points]})\n",
    "\n",
    "    linear_model = stats.lm(\"y ~ x1 + x2 + z\", data=df)\n",
    "    p_model = stats.glm(\"z ~ x1 + x2\", data=df, family=stats.binomial())\n",
    "\n",
    "    alpha = np.arange(-4500, 4500, 250)\n",
    "    ll_sens = causalsens.causalsens(linear_model, p_model, ro.Formula('~ x1 + x2'),\n",
    "                                    data=df, alpha=alpha, confound=causalsens.one_sided_att)\n",
    "    grdevices.png(file=\"assets/sensitivity_plots/amt_confounding_\" + str(num_points) + \".png\",\n",
    "                  width=512, height=512)\n",
    "    ro.r.plot(ll_sens, type=\"raw\", bty=\"n\")\n",
    "    grdevices.dev_off();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we only have 100 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(dset, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/sensitivity_plots/amt_confounding_100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we only have 200 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(dset, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/sensitivity_plots/amt_confounding_200.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have 500 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(dset, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/sensitivity_plots/amt_confounding_500.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the confidence intervals of the estimated effect shrink with an increase in the size of the dataset. For 200 and 500 datapoints, the confidence interval does not contain the true effect for many values of confounding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
